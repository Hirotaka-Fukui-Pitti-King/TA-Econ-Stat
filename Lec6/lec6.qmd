---
title: "第6回講義コード解説"
subtitle: "2025年度 神戸大学経済学部・経済統計学"
date: today
date-format: "YYYY年M月D日"
author:
  - name: "Hirotaka Fukui"
    email: "227e127e@gsuite.kobe-u.ac.jp"
    affiliations:
      - name: "Kobe University, Graduate School of Economics"

thanks: |
  神戸大学大学院経済学研究科博士後期課程.  
  227e127e@gsuite.kobe-u.ac.jp.  
  無断転載を禁じます.  
  本資料に含まれる誤りはすべて筆者の責任によるものです.  
  内容の正確性を期しておりますが、誤りや印刷上の不備がないことを保証するものではありません。  
  もし誤りを見つけられた場合は、どうぞご連絡ください。

format:
  html:
    theme: default
    mainfont: "Noto Serif JP"
    sansfont: "IBM Plex Sans JP"
    number-sections: true
execute:
  echo: true          
jupyter: nbstata      
brand:
  typography:
    fonts:
      - family: "Noto Serif JP"
        source: google
      - family: "IBM Plex Sans JP"
        source: google
    base: "Noto Serif JP"
    headings:
      family: "IBM Plex Sans JP"
      weight: regular
---

# 2項選択モデルの推定

### データのインポート
```{stata}
clear all
set more off

import delimited 6-1.csv, clear

rename v1 y //データセットを読み込むとv1という変数名になってしまうようなのでyに変えておきます。

list
```

### 2項プロビットモデルの推定
```{stata}
probit y age kids
```

解説:

- `probit`: 2項Probitモデルを推定するコマンドです。
  - 被説明(従属)変数：`y`（0/1の二値変数であることを想定）
  - 説明(独立)変数：`age, kids`

### 2項ロジットモデルの推定
```{stata}
logit y age kids
```

解説:

- `logit`: 2項Logitモデルを推定するコマンドです。
  - 被説明(従属)変数：`y`
  - 説明(独立)変数：`age, kids`

### データの保存
```{stata}
save 6-1.dta, replace
```


# 順序付き多項選択モデルの推定

### データのインポート
```{stata}
clear all
set more off

import delimited 6-2.csv, clear

list
```

### 順序付きプロビットモデルの推定
```{stata}
oprobit leng c18 ed
```

解説:

- `oprobit`: **O**rdinal **Probit**（順序付きProbit）モデルを推定します。
  - 被説明変数：`leng`: 選択肢間に順序がついているデータであることが前提
  - 説明変数: `c18、ed`

### 順序付きロジットモデルの推定
```{stata}
ologit leng c18 ed
```

解説:

- `ologit`: **O**rdinal **Logit**（順序付きLogit）モデルを推定します。
  - 被説明変数：`leng`: 選択肢間に順序がついているデータであることが前提
  - 説明変数: `c18、ed`

### データの保存
```{stata}
save 6-2.dta, replace
```

# StataにおけるProbit/Logitモデル推定結果の"Coefficient"について

## Probit/Logitモデル推定における被説明変数は何か?

上のコードでProbitやLogitモデルを推定するコードとして

```
probit y age kids
```

や

```
logit y age kids
```

を使いました。ここではデータ`y`を被説明変数として指定しているわけですが、実際のprobit/logitモデルにおける被説明変数は (2項モデルの場合) データ`y`が1となる確率

$$
\text{P}(y=1) 
$$

です [^prob]。そのもとでモデルを

$$
\text{P}(y=1) = F(\alpha + \beta \text{age} + \gamma \text{kids})
$$

として推定しています。$F(\cdot)$ は正規分布などの分布関数です。


[^prob]: 正確には「説明変数 $X$ が与えられたもとで被説明変数 $Y$ が1をとる条件付き確率 $\text{P}(Y=1|X)$ です。

## Probit/Logitモデル推定における係数(パラメータ)と限界効果

通常の線形モデル

$$
Y_{i} = \alpha + \beta X_{i} + u_{i}
$$

では推定される係数 $\beta$ は被説明変数 $Y_{i}$ に対する説明変数 $X_{i}$ の影響度合いを表す**限界効果**、つまり説明変数が1単位変化したときの被説明変数の変化 $\partial Y_{i}/\partial X_{i}$ として解釈ができます。

しかし、非線形モデルであるProbit/Logitモデルでは推定される係数 $\beta$ を被説明変数 $\text{P}(y=1)$ に対する限界効果として単純に解釈することができません。

したがってプロビットモデルやロジットモデルの推定結果を読み取る際には、結果に載っている推定値が**係数(パラメータ)**なのか**限界効果**なのかを区別することが重要になります。

- 係数(パラメータ)の推定値: 数値自体には意味はあまりなく、統計的な有意性や符号条件のみを解釈する。
- 限界効果: 説明変数が1単位変化したとき、被説明変数が1になる確率がどれくらい変化するかという影響度合いとして解釈する [^marginal]。

[^marginal]: 2項モデルの場合はこのような解釈になります。多項モデルの場合は順序付きの場合はほとんど同じです。順序なしの場合は少し複雑になります。詳しくは第7講で。

## StataにおけるProbit/Logitモデル推定`Coefficient`は「係数（パラメータそのもの）」であり、限界効果ではない

Stataではlogit や probit の推定結果には最尤法で推定された**係数（パラメータそのもの）**が表示されます。

限界効果がほしい場合は `margins` コマンドを使う必要があります。

```{stata}
clear all
set more off

import delimited 6-1.csv, clear

rename v1 y //データセットを読み込むとv1という変数名になってしまうようなのでyに変えておきます。
```

```{stata}
probit y age kids
```

**(平均)限界効果を取り出す**

```{stata}
margins, dydx(age kids)
```

平均限界効果（Average Marginal Effects）とは

- 個々の観測値ごとに限界効果を計算
- それらを平均したもの

**解釈**

1. age の限界効果は 0 に非常に近く、有意ではない
   - ageが1歳増えても $y=1$ になる確率がほぼ変わらない
2. kids（子どもの数）の限界効果は $−0.3$ 付近で大きく負
    - 子どもの人数を 1 人増やすと $y=1$ になる確率が 約30%低下

# Probit/Logitモデル推定における誤差項とは何か?

個別に質問があったので回答を共有しておきます。議論の単純化のため、2項モデルの場合を前提にします。

## 線形確率モデル

probitやlogitモデルを使うようなデータの特徴は**被説明変数が0/1などのダミー変数**であるところです。

つまり、「被説明変数 $Y$ を $0, 1$ をとるダミー変数」の場合に

$$
Y_{i} = \alpha + \beta X_{i} +u_{i}
$$

を推定すると考えることもできます。この時、$Y_{i}=1$ となる確率を $P(Y=1)$ とすると $Y$ の期待値は

$$
E[Y_{i}] = P(Y=1) × 1 + (1-P(Y=1)) × 0 = P(Y=1)
$$

すなわち

$$
E[Y_{i}] = P(Y=1) = \alpha + \beta X_{i}
$$


となるので($u_{i}$ の期待値は0なので)、もともとの推定式は

「$Y=1$ となる確率を $X$ で説明する」

というモデルと解釈できます。この時、誤差項 $u$ は

$$
u_{i} = Y_{i} - \alpha - \beta X_{i} = Y_{i} - P(Y=1)
$$

と書けるので $Y=1$ なら $u=1-P(Y=1)$, $Y=0$ ならば $u=-P(Y=1)$ となります。

つまり、$u$ は

**「実際のYの結果」 - 「モデルによるYの予測確率」**

を表しているといえます

つまり、

- モデルは「確率 $P = \alpha + \beta X_{i}$ 」を予測
- 実際には「$Y=0 \text{or} 1$ 」という離散的な結果が観測される
- そのズレが $u$

具体例で考えると

例: ある人が大学進学する確率をモデルで推定

- モデルの予測: $P = \alpha + \beta X_{i}=0.7$ (70%の確率で進学)
- 実際の結果: $Y = 1$ (実際に進学した)
- 誤差項: $u = 1 - 0.7 = 0.3$

なので $u$ はそのずれを表しているといえます。

## 潜在変数モデル

一方、プロビット/ロジットモデルでは、確率を非線形関数 $F()$ で表します：
$$
P(Y_{i}=1)=F(\alpha + \beta X_{i})
$$

Probit/Logit のモデルには直接には誤差項は出てきません。なぜならこれは 「$Y=1$ となる確率の式を推定する」モデルで、確率は誤差を「平均した結果」だからです。

プロビットモデルとロジットモデルにおける誤差項とは「観測されない**潜在変数**に付く誤差項」のことになります。

2項プロビット/ロジットモデルの背後にある考え方として、データを分析する側には観察されない $Y^{*}$ という潜在的な変数があったとして、それが説明変数 $X$をつかって

$$
Y^{*} = \alpha + \beta X_{i} +u_{i}
$$


と書けると考えます。

この時に

$$
Y_{i} =
\begin{cases}
1 & Y^{*} = bX+u>0 \\
0 & \text{それ以外}
\end{cases}
$$

というルールで $Y_{i}$ が1もしくは0をとっていると考えます。

この考えのもとで

$$
P(Y_{i}=1)=F(\alpha + \beta X_{i})
$$

を推定するのがプロビット/ロジットモデルです。

観測レベルでは、$Y$ は 0か1 のどちらかしかとりません。分析者が知りたいのは、

「どんな要因（$X$）があると $Y=1 (0)$ になりやすいか？」

です。そのために

「$X$ という説明要因があったときにY=1となる確率」$P(Y=1)$

を推定しようとします。

例として

- $X$: 親の所得
- $Y$:  大学進学（1）or 非進学（0）

を考えます。

親の所得が $X$ 万円の家庭を考えると：

- 学生A：$Y=1$（進学）
- 学生B：$Y=0$（非進学）
- 学生C：$Y=1$（進学）

というデータが得られたとします。

この時それぞれの学生には、それぞれ親の所得では説明できない事情があるはずです：

- A：奨学金が取れた（+要因）
- B：家族の介護（−要因）
- C：強い本人の意志（+要因）

親の所得とそれ以外の要因(誤差項)によって学生の進学選択を決める潜在的な要因 $Y^{*}$ が決定され、それによって進学行動 $Y=1 (0)$ が回答として出てきていると考えているわけです。

なのでプロビット/ロジットモデルにおける誤差項は線形モデルと同じようには考えることができないわけです。








